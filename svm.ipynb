{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "from cvxopt import matrix,solvers\n",
    "from scipy.spatial.distance import cdist,pdist,squareform\n",
    "import multiprocessing\n",
    "\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sample):\n",
    "    sample =  (cv2.resize(sample, (16, 16)))/255.0\n",
    "    return sample.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sample(path):\n",
    "    sample = cv2.imread(path)\n",
    "    return preprocess(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0 = 1\n",
    "class1 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train/1/4271.jpg\n"
     ]
    }
   ],
   "source": [
    "for iter, file in enumerate(glob.glob(f'./train/{class0}/*.jpg')):\n",
    "    if iter == 0:\n",
    "        print(file)\n",
    "        X0 = read_sample(file)\n",
    "    else:\n",
    "        X0 = np.vstack((X0, read_sample(file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2380, 768)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulising_factor = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train/2/21230.jpg\n"
     ]
    }
   ],
   "source": [
    "for iter, file in enumerate(glob.glob(f'./train/{class1}/*.jpg')):\n",
    "    if iter == 0:\n",
    "        X1 = read_sample(file)\n",
    "        print(file)\n",
    "    else:\n",
    "        X1 = np.vstack((X1, read_sample(file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2380, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00784314, 0.13333333, 0.01960784, ..., 0.09019608, 0.11764706,\n",
       "        0.06666667],\n",
       "       [0.09019608, 0.26666667, 0.2745098 , ..., 0.11372549, 0.18431373,\n",
       "        0.2       ],\n",
       "       [0.50588235, 0.49411765, 0.4627451 , ..., 0.36078431, 0.37647059,\n",
       "        0.41960784],\n",
       "       ...,\n",
       "       [0.39215686, 0.42745098, 0.38823529, ..., 0.01960784, 0.03921569,\n",
       "        0.03137255],\n",
       "       [0.10196078, 0.42745098, 0.37254902, ..., 0.06666667, 0.18039216,\n",
       "        0.21568627],\n",
       "       [0.02352941, 0.07843137, 0.09019608, ..., 0.05490196, 0.11764706,\n",
       "        0.18431373]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00784314, -0.13333333, -0.01960784, ..., -0.09019608,\n",
       "        -0.11764706, -0.06666667],\n",
       "       [-0.09019608, -0.26666667, -0.2745098 , ..., -0.11372549,\n",
       "        -0.18431373, -0.2       ],\n",
       "       [-0.50588235, -0.49411765, -0.4627451 , ..., -0.36078431,\n",
       "        -0.37647059, -0.41960784],\n",
       "       ...,\n",
       "       [-0.39215686, -0.42745098, -0.38823529, ..., -0.01960784,\n",
       "        -0.03921569, -0.03137255],\n",
       "       [-0.10196078, -0.42745098, -0.37254902, ..., -0.06666667,\n",
       "        -0.18039216, -0.21568627],\n",
       "       [-0.02352941, -0.07843137, -0.09019608, ..., -0.05490196,\n",
       "        -0.11764706, -0.18431373]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-1*X0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4760, 4760)\n",
      "(4760, 1)\n"
     ]
    }
   ],
   "source": [
    "only_X_data = np.vstack((X0, X1))\n",
    "\n",
    "all_X = np.vstack((-1*X0, X1))\n",
    "y = np.vstack((-1*np.ones((X0.shape[0], 1)), np.ones((X1.shape[0], 1))))\n",
    "\n",
    "negative_test_cases = X0.shape[0]\n",
    "positive_test_cases = X1.shape[0]\n",
    "number_of_test_case = all_X.shape[0]\n",
    "\n",
    "P = np.dot(all_X, all_X.T)\n",
    "print(P.shape)\n",
    "\n",
    "q = -1*np.ones((number_of_test_case, 1))\n",
    "print(q.shape)\n",
    "# q = q.T\n",
    "\n",
    "# P = -1*P\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9520, 4760) (9520, 1)\n"
     ]
    }
   ],
   "source": [
    "G = np.vstack((-1*np.eye(number_of_test_case), np.eye(number_of_test_case)))\n",
    "h = np.vstack((np.zeros((number_of_test_case, 1)), regulising_factor*np.ones((number_of_test_case, 1))))\n",
    "print(G.shape, h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4760)\n"
     ]
    }
   ],
   "source": [
    "A =  np.hstack((-1*np.ones((1, negative_test_cases)), np.ones((1, positive_test_cases))))\n",
    "print(A.shape)\n",
    "b = np.zeros((1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = matrix(P, tc='d')\n",
    "q = matrix(q, tc='d')\n",
    "G = matrix(G, tc='d')\n",
    "h = matrix(h, tc='d')\n",
    "A = matrix(A, tc='d')\n",
    "b = matrix(b, tc='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.0489e+03 -1.2518e+04  8e+04  3e+00  4e-11\n",
      " 1: -6.8322e+02 -8.0216e+03  2e+04  5e-01  4e-11\n",
      " 2: -4.8967e+02 -3.1466e+03  4e+03  1e-01  2e-11\n",
      " 3: -4.0304e+02 -1.5654e+03  2e+03  5e-02  2e-11\n",
      " 4: -3.7361e+02 -7.7703e+02  6e+02  1e-02  2e-11\n",
      " 5: -3.8001e+02 -5.4972e+02  2e+02  4e-03  2e-11\n",
      " 6: -3.9526e+02 -4.6864e+02  8e+01  1e-03  2e-11\n",
      " 7: -4.0571e+02 -4.3399e+02  3e+01  2e-04  2e-11\n",
      " 8: -4.1139e+02 -4.2094e+02  1e+01  1e-05  2e-11\n",
      " 9: -4.1426e+02 -4.1682e+02  3e+00  3e-06  2e-11\n",
      "10: -4.1514e+02 -4.1559e+02  5e-01  2e-13  2e-11\n",
      "11: -4.1533e+02 -4.1537e+02  3e-02  2e-13  2e-11\n",
      "12: -4.1535e+02 -4.1535e+02  7e-04  3e-13  2e-11\n",
      "13: -4.1535e+02 -4.1535e+02  1e-05  2e-13  2e-11\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "sol = solvers.qp(P,q,G,h,A,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = np.array(sol['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671\n"
     ]
    }
   ],
   "source": [
    "number_of_supp_vectors = np.sum(solution > 1e-6)\n",
    "print(number_of_supp_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_with_non_zero_alphas = solution.copy()\n",
    "solution_with_non_zero_alphas[solution_with_non_zero_alphas < 1e-6] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_alphas = y*solution_with_non_zero_alphas\n",
    "weights = np.dot(the_alphas.T, only_X_data).T\n",
    "b = np.mean(y - np.dot(only_X_data,weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  [[ 0.33829301]\n",
      " [-0.26910453]\n",
      " [ 0.45842852]\n",
      " [ 1.22820353]\n",
      " [-0.41419856]\n",
      " [-0.62812013]\n",
      " [ 0.27813785]\n",
      " [-0.12548144]\n",
      " [ 0.12764424]\n",
      " [ 0.30380884]\n",
      " [-0.32458783]\n",
      " [-0.12996054]\n",
      " [ 0.40146463]\n",
      " [-0.45321825]\n",
      " [ 0.08664593]\n",
      " [ 0.03842593]\n",
      " [-0.45694275]\n",
      " [ 0.39767928]\n",
      " [-0.37417386]\n",
      " [-0.58534695]\n",
      " [ 0.74742418]\n",
      " [ 0.08005849]\n",
      " [-0.59831858]\n",
      " [ 0.4050871 ]\n",
      " [ 0.17143342]\n",
      " [-0.27094614]\n",
      " [ 0.27104399]\n",
      " [ 0.29055994]\n",
      " [-0.47397033]\n",
      " [ 0.13617692]\n",
      " [-0.15716963]\n",
      " [-0.58033581]\n",
      " [ 0.49376764]\n",
      " [-0.22674986]\n",
      " [-0.38627233]\n",
      " [ 0.36119057]\n",
      " [ 0.96171373]\n",
      " [-0.14109074]\n",
      " [-0.1724775 ]\n",
      " [ 1.22362283]\n",
      " [-0.40372132]\n",
      " [-0.25394422]\n",
      " [ 1.04778586]\n",
      " [-0.61972547]\n",
      " [-0.20429805]\n",
      " [ 0.13061751]\n",
      " [-0.32518196]\n",
      " [ 0.3474874 ]\n",
      " [ 0.92676973]\n",
      " [-0.09994707]\n",
      " [-0.56315033]\n",
      " [ 1.51370532]\n",
      " [-0.00866827]\n",
      " [-0.55076057]\n",
      " [ 0.21050943]\n",
      " [-0.39908061]\n",
      " [ 0.04385673]\n",
      " [-0.06427645]\n",
      " [-0.18405081]\n",
      " [-0.16802644]\n",
      " [ 0.48596055]\n",
      " [ 0.35493829]\n",
      " [-0.19524448]\n",
      " [ 0.03691451]\n",
      " [ 0.13738083]\n",
      " [-0.6458985 ]\n",
      " [ 0.35753238]\n",
      " [ 0.05108147]\n",
      " [-0.20108666]\n",
      " [ 0.00887242]\n",
      " [-0.20611624]\n",
      " [ 0.55326421]\n",
      " [ 0.0918569 ]\n",
      " [-0.67137879]\n",
      " [-0.44765971]\n",
      " [ 0.43873316]\n",
      " [-0.20395471]\n",
      " [-0.0333959 ]\n",
      " [ 0.10593529]\n",
      " [-0.41519873]\n",
      " [ 0.30242745]\n",
      " [ 0.23002857]\n",
      " [-0.06471737]\n",
      " [-0.11501485]\n",
      " [-0.06153257]\n",
      " [-0.05076986]\n",
      " [ 0.39168994]\n",
      " [ 0.4899759 ]\n",
      " [-0.42979141]\n",
      " [ 0.04218727]\n",
      " [-0.12340167]\n",
      " [ 0.01930729]\n",
      " [ 0.26936967]\n",
      " [-0.63465374]\n",
      " [-0.09893039]\n",
      " [ 0.72338062]\n",
      " [ 0.49756508]\n",
      " [-0.06450275]\n",
      " [ 0.21198296]\n",
      " [ 0.29152168]\n",
      " [-0.26980162]\n",
      " [-0.41774795]\n",
      " [ 0.04932939]\n",
      " [ 0.04533724]\n",
      " [ 0.36005316]\n",
      " [-0.44817388]\n",
      " [ 0.25631001]\n",
      " [ 0.10336033]\n",
      " [-0.17086579]\n",
      " [-0.02684956]\n",
      " [-0.19781099]\n",
      " [-0.5029784 ]\n",
      " [-0.18961693]\n",
      " [ 0.39763626]\n",
      " [ 0.1003413 ]\n",
      " [-0.22080885]\n",
      " [-0.27393682]\n",
      " [ 0.00778854]\n",
      " [-0.51781668]\n",
      " [-0.04628721]\n",
      " [ 0.05744133]\n",
      " [-0.01614187]\n",
      " [ 0.15655663]\n",
      " [ 0.15878864]\n",
      " [-0.46022099]\n",
      " [-0.03910249]\n",
      " [ 0.15933672]\n",
      " [ 0.08082807]\n",
      " [ 0.32606054]\n",
      " [ 0.33196796]\n",
      " [-0.06426322]\n",
      " [-0.18294137]\n",
      " [ 0.04825483]\n",
      " [-0.19306741]\n",
      " [ 0.48394354]\n",
      " [ 0.05236124]\n",
      " [-0.68907795]\n",
      " [ 0.19681875]\n",
      " [ 0.76099594]\n",
      " [-0.28477574]\n",
      " [-0.21065857]\n",
      " [ 0.52250857]\n",
      " [-0.00580449]\n",
      " [ 0.08609356]\n",
      " [ 0.04058847]\n",
      " [-0.7221428 ]\n",
      " [-0.18799514]\n",
      " [-0.35249968]\n",
      " [-0.07103226]\n",
      " [ 0.03534646]\n",
      " [-0.27726796]\n",
      " [ 0.0868769 ]\n",
      " [ 0.2792489 ]\n",
      " [-0.20320713]\n",
      " [ 0.15038444]\n",
      " [-0.34343103]\n",
      " [-0.09263399]\n",
      " [ 0.4308357 ]\n",
      " [ 0.06677609]\n",
      " [ 0.55454053]\n",
      " [ 0.08444587]\n",
      " [-0.11683763]\n",
      " [-0.23588007]\n",
      " [-0.22931201]\n",
      " [ 0.25932905]\n",
      " [-0.32666377]\n",
      " [ 0.19675201]\n",
      " [ 0.21281087]\n",
      " [-0.01750529]\n",
      " [ 0.23492157]\n",
      " [-0.022742  ]\n",
      " [-0.11417412]\n",
      " [-0.0662985 ]\n",
      " [ 0.01445015]\n",
      " [ 0.48791259]\n",
      " [-0.56404766]\n",
      " [ 0.06159002]\n",
      " [-0.18010558]\n",
      " [-0.47161924]\n",
      " [ 0.12286931]\n",
      " [ 0.07489972]\n",
      " [-0.30038956]\n",
      " [-0.02570582]\n",
      " [-0.05028933]\n",
      " [-0.29289966]\n",
      " [ 0.28419915]\n",
      " [ 0.13125742]\n",
      " [-0.23489985]\n",
      " [ 0.49450763]\n",
      " [-0.10239834]\n",
      " [-0.12013563]\n",
      " [-0.07080347]\n",
      " [ 0.10759659]\n",
      " [-0.18573598]\n",
      " [-0.31917561]\n",
      " [-0.10757791]\n",
      " [ 0.46598761]\n",
      " [ 0.17165517]\n",
      " [-0.5798246 ]\n",
      " [ 0.15736914]\n",
      " [ 0.08175421]\n",
      " [ 0.06572672]\n",
      " [ 0.03058191]\n",
      " [ 0.12253045]\n",
      " [ 0.22144957]\n",
      " [-0.37804908]\n",
      " [ 0.06824751]\n",
      " [ 0.54170452]\n",
      " [-0.07603455]\n",
      " [-0.85748932]\n",
      " [ 0.3036271 ]\n",
      " [ 0.30767884]\n",
      " [-0.12199073]\n",
      " [-0.03195584]\n",
      " [ 0.30129496]\n",
      " [-0.21551611]\n",
      " [ 0.26760237]\n",
      " [ 0.38940475]\n",
      " [-0.25890316]\n",
      " [ 0.57349639]\n",
      " [-0.10022225]\n",
      " [-0.51762045]\n",
      " [ 0.59901831]\n",
      " [-0.3077534 ]\n",
      " [-0.02370117]\n",
      " [ 0.19062986]\n",
      " [-0.10014369]\n",
      " [ 0.25439467]\n",
      " [-0.46523446]\n",
      " [ 0.09887632]\n",
      " [-0.10419244]\n",
      " [-0.54767934]\n",
      " [ 0.10803463]\n",
      " [ 0.25956506]\n",
      " [-0.03403993]\n",
      " [ 0.20698716]\n",
      " [-0.24052636]\n",
      " [-0.02337303]\n",
      " [ 0.45808998]\n",
      " [-0.1944305 ]\n",
      " [ 0.51127049]\n",
      " [ 0.12195004]\n",
      " [-0.22986863]\n",
      " [ 0.78317728]\n",
      " [-0.48642113]\n",
      " [-0.20694354]\n",
      " [-0.19537151]\n",
      " [-0.37644115]\n",
      " [ 0.8142675 ]\n",
      " [ 0.609233  ]\n",
      " [ 0.01032874]\n",
      " [ 0.03911117]\n",
      " [ 0.73951821]\n",
      " [-0.82354454]\n",
      " [-0.33987745]\n",
      " [ 0.19810934]\n",
      " [ 0.18206136]\n",
      " [ 0.12266463]\n",
      " [-0.03187435]\n",
      " [-0.4157414 ]\n",
      " [ 0.23254488]\n",
      " [-0.73446359]\n",
      " [-0.0879977 ]\n",
      " [ 0.81296376]\n",
      " [-0.3611287 ]\n",
      " [-0.17991198]\n",
      " [ 0.37450969]\n",
      " [-0.3735206 ]\n",
      " [-0.1611261 ]\n",
      " [ 0.8020976 ]\n",
      " [ 0.08533127]\n",
      " [-0.65341135]\n",
      " [ 0.20764562]\n",
      " [-0.18044569]\n",
      " [ 0.27061652]\n",
      " [ 0.3212513 ]\n",
      " [ 0.84839983]\n",
      " [-0.15365506]\n",
      " [-0.42039225]\n",
      " [-0.02654318]\n",
      " [-0.17305719]\n",
      " [ 0.35768838]\n",
      " [-0.62046316]\n",
      " [-0.16442075]\n",
      " [ 0.08094503]\n",
      " [-0.00600869]\n",
      " [ 0.34933832]\n",
      " [-0.68263461]\n",
      " [-0.1517665 ]\n",
      " [ 0.0244376 ]\n",
      " [ 0.27153064]\n",
      " [-0.33996559]\n",
      " [-0.17256288]\n",
      " [ 0.43824646]\n",
      " [-0.38501922]\n",
      " [ 0.19606771]\n",
      " [-0.17267462]\n",
      " [-0.64647541]\n",
      " [ 0.37742831]\n",
      " [ 0.19786113]\n",
      " [-0.16680091]\n",
      " [ 0.06000046]\n",
      " [ 0.31645587]\n",
      " [ 0.05523978]\n",
      " [ 0.31513868]\n",
      " [-0.144331  ]\n",
      " [-0.15599127]\n",
      " [ 0.26349809]\n",
      " [-0.19929844]\n",
      " [ 0.30085038]\n",
      " [ 0.41614488]\n",
      " [-0.28291919]\n",
      " [ 0.00690548]\n",
      " [-0.15155051]\n",
      " [ 0.07113338]\n",
      " [ 0.06269424]\n",
      " [ 0.02579694]\n",
      " [ 0.13054921]\n",
      " [ 0.60123806]\n",
      " [-0.68004611]\n",
      " [ 0.14962144]\n",
      " [-0.02909151]\n",
      " [-0.11833715]\n",
      " [ 0.00987177]\n",
      " [ 0.40761157]\n",
      " [-0.0798695 ]\n",
      " [ 0.05382424]\n",
      " [-0.11327156]\n",
      " [-0.49509365]\n",
      " [ 0.45571598]\n",
      " [ 0.50033736]\n",
      " [-0.05251596]\n",
      " [-0.2648456 ]\n",
      " [ 0.13680386]\n",
      " [ 0.03864489]\n",
      " [-0.34213991]\n",
      " [-0.18385314]\n",
      " [ 0.00268561]\n",
      " [-0.07861131]\n",
      " [ 0.12113465]\n",
      " [ 0.12965544]\n",
      " [-0.41840935]\n",
      " [ 0.14596815]\n",
      " [ 0.24359851]\n",
      " [-0.61028562]\n",
      " [ 0.55851911]\n",
      " [ 0.1817088 ]\n",
      " [-0.73277059]\n",
      " [ 1.16931908]\n",
      " [-0.32386936]\n",
      " [-0.65721899]\n",
      " [-0.49941004]\n",
      " [ 0.13896422]\n",
      " [-0.11698673]\n",
      " [-0.11033262]\n",
      " [ 0.46296414]\n",
      " [-0.29631707]\n",
      " [ 0.31493077]\n",
      " [ 0.21711273]\n",
      " [-0.3537631 ]\n",
      " [-0.11883715]\n",
      " [-0.24285469]\n",
      " [ 0.17993235]\n",
      " [ 0.42154729]\n",
      " [ 0.43815755]\n",
      " [-0.33502476]\n",
      " [ 1.13104762]\n",
      " [-0.54161492]\n",
      " [-0.59881821]\n",
      " [ 0.16334959]\n",
      " [ 0.29727381]\n",
      " [-0.44285388]\n",
      " [-0.35011964]\n",
      " [ 0.16070303]\n",
      " [-0.0942639 ]\n",
      " [-0.05915269]\n",
      " [-0.14918211]\n",
      " [ 0.33619534]\n",
      " [ 0.68876303]\n",
      " [-0.43684536]\n",
      " [-0.47483161]\n",
      " [ 0.02598443]\n",
      " [-0.15898658]\n",
      " [ 0.71318305]\n",
      " [ 0.57392708]\n",
      " [-0.19846333]\n",
      " [ 0.3579023 ]\n",
      " [ 0.45380309]\n",
      " [-0.42455048]\n",
      " [-0.40782481]\n",
      " [-0.78603151]\n",
      " [ 0.23550018]\n",
      " [ 0.0024505 ]\n",
      " [ 0.09625307]\n",
      " [ 0.26409332]\n",
      " [ 0.08829738]\n",
      " [-0.08137263]\n",
      " [ 0.19233244]\n",
      " [ 0.01900929]\n",
      " [-0.40878562]\n",
      " [ 0.5481777 ]\n",
      " [ 0.64278958]\n",
      " [ 0.45447154]\n",
      " [ 0.38716463]\n",
      " [ 0.09916806]\n",
      " [-0.04577205]\n",
      " [-0.02566206]\n",
      " [-0.16909048]\n",
      " [-0.08939832]\n",
      " [ 0.43242015]\n",
      " [-0.06588936]\n",
      " [-0.13735408]\n",
      " [ 0.1156877 ]\n",
      " [-0.0261434 ]\n",
      " [ 0.7151908 ]\n",
      " [ 0.07544905]\n",
      " [-0.49021242]\n",
      " [-0.63908683]\n",
      " [ 0.3723745 ]\n",
      " [ 0.1695263 ]\n",
      " [-1.09369304]\n",
      " [ 0.60803414]\n",
      " [ 0.70933319]\n",
      " [-0.71223209]\n",
      " [ 0.16837156]\n",
      " [ 0.37739892]\n",
      " [ 0.78089442]\n",
      " [ 0.12708847]\n",
      " [-0.41511124]\n",
      " [ 0.23820486]\n",
      " [-0.28527284]\n",
      " [-0.12542995]\n",
      " [ 0.4604691 ]\n",
      " [-1.05029889]\n",
      " [ 0.79142436]\n",
      " [ 0.02159594]\n",
      " [-0.34510959]\n",
      " [ 1.09729076]\n",
      " [-0.46978275]\n",
      " [ 0.00256136]\n",
      " [ 0.06730339]\n",
      " [ 0.66722081]\n",
      " [-0.18113045]\n",
      " [-0.74547535]\n",
      " [ 0.1038357 ]\n",
      " [-0.34869059]\n",
      " [-0.1282967 ]\n",
      " [-0.11905703]\n",
      " [-0.51720676]\n",
      " [-0.27087987]\n",
      " [ 0.3946348 ]\n",
      " [ 0.11765225]\n",
      " [-0.35476297]\n",
      " [ 0.04301719]\n",
      " [ 0.09761394]\n",
      " [ 0.14843249]\n",
      " [ 0.48353014]\n",
      " [ 0.0361638 ]\n",
      " [-0.04247858]\n",
      " [ 0.55075049]\n",
      " [-0.2827161 ]\n",
      " [-0.34215771]\n",
      " [ 0.88783349]\n",
      " [-0.18850346]\n",
      " [-0.29974445]\n",
      " [ 0.0326509 ]\n",
      " [ 0.42467735]\n",
      " [-0.11599714]\n",
      " [-0.04097717]\n",
      " [ 0.2152674 ]\n",
      " [ 0.1585454 ]\n",
      " [-0.25290135]\n",
      " [-0.01718195]\n",
      " [ 0.0549826 ]\n",
      " [-0.55889901]\n",
      " [-0.02659751]\n",
      " [ 0.27318618]\n",
      " [ 0.64662996]\n",
      " [-0.26322101]\n",
      " [ 0.33951094]\n",
      " [ 0.62847294]\n",
      " [-0.41579636]\n",
      " [ 0.19941849]\n",
      " [ 0.19076318]\n",
      " [-0.20563645]\n",
      " [ 0.25159794]\n",
      " [-0.2934885 ]\n",
      " [-0.10698925]\n",
      " [-0.0039202 ]\n",
      " [ 0.49504112]\n",
      " [ 0.32161371]\n",
      " [ 0.38462117]\n",
      " [ 0.56660318]\n",
      " [-0.37375637]\n",
      " [-0.47995008]\n",
      " [-0.00707263]\n",
      " [ 0.52724551]\n",
      " [-0.17726363]\n",
      " [ 0.37869973]\n",
      " [ 0.32760574]\n",
      " [-0.5143797 ]\n",
      " [ 0.22016007]\n",
      " [-0.17482193]\n",
      " [ 0.33489968]\n",
      " [ 0.21451774]\n",
      " [ 0.04264439]\n",
      " [-0.29428085]\n",
      " [-0.08518613]\n",
      " [-0.43369798]\n",
      " [-0.14449612]\n",
      " [ 0.36902231]\n",
      " [ 0.1682109 ]\n",
      " [ 0.50533221]\n",
      " [-0.43376039]\n",
      " [ 0.68226111]\n",
      " [ 0.1235308 ]\n",
      " [-0.29008791]\n",
      " [ 0.78765829]\n",
      " [-0.52813644]\n",
      " [ 0.68446193]\n",
      " [-0.59748758]\n",
      " [-0.75871786]\n",
      " [-0.06833228]\n",
      " [-0.15782184]\n",
      " [-0.12544295]\n",
      " [-0.34744739]\n",
      " [-0.3866808 ]\n",
      " [-0.09499335]\n",
      " [ 0.37237849]\n",
      " [ 0.13191122]\n",
      " [-1.06677817]\n",
      " [ 0.14658673]\n",
      " [-0.0547737 ]\n",
      " [-0.40121902]\n",
      " [ 0.138341  ]\n",
      " [-0.54831591]\n",
      " [ 0.07471178]\n",
      " [-0.03324304]\n",
      " [-0.26303881]\n",
      " [-0.24874561]\n",
      " [ 0.04554862]\n",
      " [ 0.51217928]\n",
      " [ 0.23768813]\n",
      " [ 0.30880768]\n",
      " [ 0.95512705]\n",
      " [-0.72137459]\n",
      " [ 0.31881999]\n",
      " [-0.07074692]\n",
      " [-1.14102779]\n",
      " [-0.33446122]\n",
      " [ 0.19375693]\n",
      " [ 0.11420802]\n",
      " [-0.48698999]\n",
      " [ 0.24545622]\n",
      " [ 0.04544404]\n",
      " [ 0.13302575]\n",
      " [ 0.00165345]\n",
      " [-0.33922919]\n",
      " [ 0.78443384]\n",
      " [-0.46981441]\n",
      " [-0.28618057]\n",
      " [ 0.42589554]\n",
      " [-0.28678863]\n",
      " [-0.23978783]\n",
      " [-0.01527665]\n",
      " [ 0.46493777]\n",
      " [ 0.036014  ]\n",
      " [-0.44046553]\n",
      " [ 0.48697596]\n",
      " [-0.00781359]\n",
      " [ 0.39189498]\n",
      " [-0.10542349]\n",
      " [ 0.52519955]\n",
      " [-0.04662472]\n",
      " [-0.276716  ]\n",
      " [ 0.41075058]\n",
      " [ 0.38623929]\n",
      " [ 0.10444527]\n",
      " [-0.42994969]\n",
      " [-0.06872781]\n",
      " [-0.29118842]\n",
      " [ 0.243495  ]\n",
      " [ 0.33745408]\n",
      " [ 0.14808058]\n",
      " [ 0.04128684]\n",
      " [ 0.2102723 ]\n",
      " [-0.18577244]\n",
      " [-0.73038557]\n",
      " [ 0.42519565]\n",
      " [-0.1001515 ]\n",
      " [-0.34286257]\n",
      " [ 0.9195274 ]\n",
      " [-0.52340849]\n",
      " [ 0.09745337]\n",
      " [ 0.42950186]\n",
      " [-0.17352285]\n",
      " [-0.07101144]\n",
      " [ 0.16218756]\n",
      " [-0.14293556]\n",
      " [-0.09978492]\n",
      " [ 0.25189229]\n",
      " [-0.18238332]\n",
      " [-0.27031149]\n",
      " [-0.27555909]\n",
      " [-0.39749874]\n",
      " [ 0.4010689 ]\n",
      " [ 0.35369979]\n",
      " [-0.28644751]\n",
      " [ 0.13288288]\n",
      " [ 0.19998133]\n",
      " [-0.00932789]\n",
      " [ 0.02316084]\n",
      " [ 0.53058303]\n",
      " [-0.25813118]\n",
      " [-0.32804024]\n",
      " [-0.42240837]\n",
      " [ 0.33439635]\n",
      " [ 0.28257716]\n",
      " [ 0.26866442]\n",
      " [-0.25253097]\n",
      " [-0.13869768]\n",
      " [ 0.28729451]\n",
      " [-0.05980608]\n",
      " [ 0.38944745]\n",
      " [ 0.15826478]\n",
      " [ 0.13259132]\n",
      " [ 0.09211339]\n",
      " [-0.26918789]\n",
      " [ 0.05830212]\n",
      " [ 0.50173412]\n",
      " [-0.20992254]\n",
      " [-0.42299551]\n",
      " [ 0.95846783]\n",
      " [-0.33699869]\n",
      " [-0.11171657]\n",
      " [-0.06076906]\n",
      " [ 0.75155507]\n",
      " [-0.50024135]\n",
      " [-0.44869703]\n",
      " [ 0.04050174]\n",
      " [-0.41949859]\n",
      " [-0.31479353]\n",
      " [-0.05614482]\n",
      " [ 0.09577689]\n",
      " [ 0.08267836]\n",
      " [-0.18585817]\n",
      " [ 0.32774468]\n",
      " [-0.30954989]\n",
      " [ 0.13262906]\n",
      " [ 0.7331389 ]\n",
      " [ 0.20503591]\n",
      " [ 0.59030087]\n",
      " [-0.36993931]\n",
      " [-0.47272519]\n",
      " [ 0.11466126]\n",
      " [-0.2389387 ]\n",
      " [-0.02766759]\n",
      " [ 0.26231368]\n",
      " [-0.42683641]\n",
      " [-0.11020105]\n",
      " [ 1.06824997]\n",
      " [ 0.14082217]\n",
      " [-0.47729115]\n",
      " [ 0.59686065]\n",
      " [-0.39066683]\n",
      " [ 0.29028321]\n",
      " [ 0.02032222]\n",
      " [-0.16403683]\n",
      " [-0.28117088]\n",
      " [ 0.39842832]\n",
      " [-0.22293051]\n",
      " [-0.42515531]\n",
      " [-0.01378703]\n",
      " [ 0.11039544]\n",
      " [-0.17074393]\n",
      " [ 0.62036327]\n",
      " [ 0.46023431]\n",
      " [-0.02424255]\n",
      " [ 0.34414286]\n",
      " [-0.10602019]\n",
      " [-0.34678974]\n",
      " [-0.58488297]\n",
      " [-0.15390167]\n",
      " [-0.08797487]\n",
      " [ 0.41843507]\n",
      " [-0.09934697]\n",
      " [-0.12498923]\n",
      " [-0.45466162]\n",
      " [-0.1045031 ]\n",
      " [ 0.18161601]\n",
      " [-0.40670319]\n",
      " [ 0.88007083]\n",
      " [-0.29816195]\n",
      " [-0.29203552]\n",
      " [ 0.7929084 ]\n",
      " [ 0.08078246]\n",
      " [-0.14047821]\n",
      " [-0.37806135]\n",
      " [-0.44558146]\n",
      " [-0.40800984]\n",
      " [ 0.36223645]\n",
      " [ 0.02104464]\n",
      " [-0.11811721]\n",
      " [ 0.31316981]\n",
      " [ 0.14005208]\n",
      " [-0.7661164 ]\n",
      " [ 0.106646  ]\n",
      " [ 0.0775818 ]\n",
      " [-0.32349581]\n",
      " [-0.10941949]\n",
      " [ 0.19684315]\n",
      " [ 0.0870676 ]\n",
      " [-0.10586134]\n",
      " [ 0.05146906]\n",
      " [ 0.29436396]\n",
      " [ 0.0645878 ]\n",
      " [ 0.14112047]\n",
      " [-0.01330958]\n",
      " [ 0.54694875]\n",
      " [ 0.11015825]\n",
      " [ 0.55361167]\n",
      " [ 0.0427799 ]\n",
      " [ 0.08962899]\n",
      " [ 0.45330554]\n",
      " [-0.05544994]\n",
      " [-0.05676248]\n",
      " [ 0.1901843 ]\n",
      " [ 0.16383786]\n",
      " [-0.21632394]\n",
      " [ 0.59132835]\n",
      " [ 0.18764178]\n",
      " [-0.23143765]\n",
      " [ 0.19988719]\n",
      " [ 0.00892063]\n",
      " [-0.32169942]\n",
      " [-0.38878882]\n",
      " [ 0.33521022]\n",
      " [ 0.20564727]\n",
      " [-1.11568834]\n",
      " [ 0.04929613]\n",
      " [ 0.19340315]\n",
      " [-0.59218797]\n",
      " [ 0.78157345]\n",
      " [ 0.17947407]\n",
      " [-0.46605577]\n",
      " [-0.09556214]\n",
      " [-0.09616775]\n",
      " [-0.31429379]\n",
      " [ 0.30686629]\n",
      " [-0.29165494]\n",
      " [-0.60000244]\n",
      " [-0.02755476]\n",
      " [ 0.84474722]\n",
      " [-0.22808943]\n",
      " [ 0.47322813]\n",
      " [ 0.75132338]\n",
      " [ 0.39965812]\n",
      " [-0.07598938]\n",
      " [-0.45351528]\n",
      " [-0.30982007]\n",
      " [ 0.23197217]\n",
      " [-0.40443177]\n",
      " [-0.25366374]\n",
      " [ 0.06411378]\n",
      " [-0.24473204]\n",
      " [-0.34654095]\n",
      " [ 0.14229165]\n",
      " [ 0.10056146]]\n",
      "Bias:  -3.820619335600625\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights: \", weights)\n",
    "print(\"Bias: \", b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for iter, file in enumerate(glob.glob(f'./val/{class0}/*.jpg')):\n",
    "    total += 1 \n",
    "    validate_on = read_sample(file)\n",
    "    # print(validate_on.shape)\n",
    "    if np.dot(validate_on, weights) + b <= 0:\n",
    "        correct += 1\n",
    "        \n",
    "for iter, file in enumerate(glob.glob(f'./val/{class1}/*.jpg')):\n",
    "    total += 1 \n",
    "    validate_on = read_sample(file)\n",
    "    if np.dot(validate_on, weights) + b >= 0:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.0 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {(100*correct)/total} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Part 1(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9520, 4760) (9520, 1)\n"
     ]
    }
   ],
   "source": [
    "KERNEL_MATRIX = (np.outer(y,y))* (np.exp(-gamma * cdist(only_X_data, only_X_data, 'sqeuclidean')))\n",
    "\n",
    "# v = pdist(only_X_data, 'sqeuclidean')\n",
    "# KERNEL_MATRIX = np.exp(-1*gamma*squareform(v))\n",
    "\n",
    "q = -1*np.ones((number_of_test_case, 1))\n",
    "G = np.vstack((-1*np.eye(number_of_test_case), np.eye(number_of_test_case)))\n",
    "h = np.vstack((np.zeros((number_of_test_case, 1)), regulising_factor*np.ones((number_of_test_case, 1))))\n",
    "print(G.shape, h.shape)\n",
    "A =  np.hstack((-1*np.ones((1, negative_test_cases)), np.ones((1, positive_test_cases))))\n",
    "# print(A.shape)\n",
    "b = np.zeros((1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "KERNEL_MATRIX = matrix(KERNEL_MATRIX, tc='d')\n",
    "q = matrix(q, tc='d')\n",
    "G = matrix(G, tc='d')\n",
    "h = matrix(h, tc='d')\n",
    "A = matrix(A, tc='d')\n",
    "b = matrix(b, tc='d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1860e+03 -1.2578e+04  7e+04  3e+00  2e-13\n",
      " 1: -7.3522e+02 -8.1296e+03  1e+04  4e-01  3e-13\n",
      " 2: -5.6455e+02 -1.6716e+03  1e+03  8e-03  2e-13\n",
      " 3: -6.6510e+02 -1.3790e+03  7e+02  5e-03  2e-13\n",
      " 4: -7.4937e+02 -1.1580e+03  4e+02  2e-03  2e-13\n",
      " 5: -7.7440e+02 -1.1039e+03  3e+02  2e-03  2e-13\n",
      " 6: -8.0472e+02 -1.0385e+03  2e+02  9e-04  2e-13\n",
      " 7: -8.3295e+02 -9.7750e+02  1e+02  3e-04  2e-13\n",
      " 8: -8.4698e+02 -9.5141e+02  1e+02  2e-04  2e-13\n",
      " 9: -8.6050e+02 -9.2677e+02  7e+01  1e-04  2e-13\n",
      "10: -8.7205e+02 -9.0692e+02  4e+01  5e-05  2e-13\n",
      "11: -8.7866e+02 -8.9617e+02  2e+01  2e-05  2e-13\n",
      "12: -8.8279e+02 -8.8974e+02  7e+00  6e-06  2e-13\n",
      "13: -8.8527e+02 -8.8638e+02  1e+00  8e-07  3e-13\n",
      "14: -8.8573e+02 -8.8578e+02  5e-02  2e-08  3e-13\n",
      "15: -8.8576e+02 -8.8576e+02  1e-03  6e-10  3e-13\n",
      "16: -8.8576e+02 -8.8576e+02  3e-05  1e-11  3e-13\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "kernel_sol = solvers.qp(KERNEL_MATRIX,q,G,h,A,b)\n",
    "# only_X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_solution = np.array(kernel_sol['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1096\n"
     ]
    }
   ],
   "source": [
    "number_of_supp_vectors = np.sum(kernel_solution > 1e-6)\n",
    "print(number_of_supp_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.01777784e-09],\n",
       "       [1.32327817e-09],\n",
       "       [9.99999998e-01],\n",
       "       ...,\n",
       "       [3.92286634e-09],\n",
       "       [1.49205752e-09],\n",
       "       [2.76835478e-09]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_on_gaussian(X_to_infer_on, X_used_for_training,alpha_i_s,y,gamma = 0.001):\n",
    "    KERNEL_MATRIX = (np.exp(-gamma * cdist(X_used_for_training, X_used_for_training, 'sqeuclidean')))\n",
    "    bias = np.mean(y - np.dot(KERNEL_MATRIX,alpha_i_s*y))\n",
    "    \n",
    "    KERNEL_TO_INFER = (np.exp(-gamma * cdist(X_used_for_training, X_to_infer_on, 'sqeuclidean')))\n",
    "    predictions = np.dot(KERNEL_TO_INFER.T, (alpha_i_s*y)) + bias\n",
    "\n",
    "    # predictions = [1 if pred >=0 else -1 for pred in predictions]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.75 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "infer_actual = []\n",
    "\n",
    "for iter, file in enumerate(glob.glob(f'./val/{class0}/*.jpg')):\n",
    "    total += 1 \n",
    "    validate_on = read_sample(file)\n",
    "    if iter == 0:\n",
    "        X_to_infer_on = validate_on\n",
    "    else:\n",
    "        X_to_infer_on = np.vstack((X_to_infer_on, validate_on))\n",
    "    infer_actual.append(-1)\n",
    "        \n",
    "for iter, file in enumerate(glob.glob(f'./val/{class1}/*.jpg')):\n",
    "    total += 1 \n",
    "    validate_on = read_sample(file)\n",
    "    X_to_infer_on = np.vstack((X_to_infer_on, validate_on))\n",
    "    infer_actual.append(1)\n",
    "\n",
    "predictions = infer_on_gaussian(X_to_infer_on, only_X_data,kernel_solution,y,gamma = 0.001)\n",
    "predictions = [1 if pred >=0 else -1 for pred in predictions]\n",
    "\n",
    "\n",
    "for pred, actual in zip(predictions, infer_actual):\n",
    "    if pred == actual:\n",
    "        correct += 1\n",
    "\n",
    "print(f\"Accuracy: {(100*correct)/total} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "ski_svm = svm.SVC(kernel='linear')\n",
    "ski_svm.fit(np.vstack((X0, X1)), np.hstack((np.zeros((X0.shape[0])), np.ones((X1.shape[0])))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of support vectors for class 0: 346\n",
      "Number of support vectors for class 1: 321\n"
     ]
    }
   ],
   "source": [
    "support_vectors_per_class = ski_svm.n_support_\n",
    "\n",
    "num_support_vectors_class_0 = support_vectors_per_class[0]\n",
    "num_support_vectors_class_1 = support_vectors_per_class[1]\n",
    "\n",
    "print(f\"Number of support vectors for class 0: {num_support_vectors_class_0}\")\n",
    "print(f\"Number of support vectors for class 1: {num_support_vectors_class_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for iter, file in enumerate(glob.glob(f'./val/{class0}/*.jpg')):\n",
    "    total += 1 \n",
    "    validate_on = read_sample(file)\n",
    "    # print(ski_svm.predict([validate_on]))\n",
    "    if ski_svm.predict([validate_on]) == 0:\n",
    "        correct += 1\n",
    "        \n",
    "for iter, file in enumerate(glob.glob(f'./val/{class1}/*.jpg')):\n",
    "    total += 1 \n",
    "    validate_on = read_sample(file)\n",
    "    if ski_svm.predict([validate_on]) == 1:\n",
    "        correct += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SKLearn: 92.0 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy with SKLearn: {(100*correct)/total} %\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Support Vectors: 1087\n"
     ]
    }
   ],
   "source": [
    "ski_svm_gauss = svm.SVC(kernel='rbf', gamma=gamma)\n",
    "\n",
    "ski_svm_gauss.fit(np.vstack((X0, X1)), np.hstack((np.zeros((X0.shape[0])), np.ones((X1.shape[0])))))\n",
    "\n",
    "num_support_vectors = len(ski_svm_gauss.support_vectors_)\n",
    "print(f\"Number of Support Vectors: {num_support_vectors}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for iter, file in enumerate(glob.glob(f'./val/{class0}/*.jpg')):\n",
    "    total += 1 \n",
    "    validate_on = read_sample(file)\n",
    "    # print(ski_svm.predict([validate_on]))\n",
    "    if ski_svm_gauss.predict([validate_on]) == 0:\n",
    "        correct += 1\n",
    "        \n",
    "for iter, file in enumerate(glob.glob(f'./val/{class1}/*.jpg')):\n",
    "    total += 1 \n",
    "    validate_on = read_sample(file)\n",
    "    if ski_svm_gauss.predict([validate_on]) == 1:\n",
    "        correct += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with SKLearn on gaussian is: 93.75 %\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy with SKLearn on gaussian is: {(100*correct)/total} %\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_between_two(class0,class1):\n",
    "    print(\"Classifying between \", class0, \" and \", class1)\n",
    "    for iter, file in enumerate(glob.glob(f'./train/{class0}/*.jpg')):\n",
    "        if iter == 0:\n",
    "            # print(file)\n",
    "            X0 = read_sample(file)\n",
    "        else:\n",
    "            X0 = np.vstack((X0, read_sample(file)))\n",
    "        \n",
    "    for iter, file in enumerate(glob.glob(f'./train/{class1}/*.jpg')):\n",
    "        if iter == 0:\n",
    "            X1 = read_sample(file)\n",
    "            print(file)\n",
    "        else:\n",
    "            X1 = np.vstack((X1, read_sample(file)))\n",
    "    \n",
    "    only_X_data = np.vstack((X0, X1))\n",
    "\n",
    "    all_X = np.vstack((-1*X0, X1))\n",
    "    y = np.vstack((-1*np.ones((X0.shape[0], 1)), np.ones((X1.shape[0], 1))))\n",
    "\n",
    "    negative_test_cases = X0.shape[0]\n",
    "    positive_test_cases = X1.shape[0]\n",
    "    number_of_test_case = all_X.shape[0]\n",
    "\n",
    "    gamma = 0.001\n",
    "    \n",
    "    KERNEL_MATRIX = (np.outer(y,y))* (np.exp(-gamma * cdist(only_X_data, only_X_data, 'sqeuclidean')))\n",
    "    \n",
    "    q = -1*np.ones((number_of_test_case, 1))\n",
    "    G = np.vstack((-1*np.eye(number_of_test_case), np.eye(number_of_test_case)))\n",
    "    h = np.vstack((np.zeros((number_of_test_case, 1)), regulising_factor*np.ones((number_of_test_case, 1))))\n",
    "    A =  np.hstack((-1*np.ones((1, negative_test_cases)), np.ones((1, positive_test_cases))))\n",
    "    b = np.zeros((1))\n",
    "    \n",
    "    \n",
    "    KERNEL_MATRIX = matrix(KERNEL_MATRIX, tc='d')\n",
    "    q = matrix(q, tc='d')\n",
    "    G = matrix(G, tc='d')\n",
    "    h = matrix(h, tc='d')\n",
    "    A = matrix(A, tc='d')\n",
    "    b = matrix(b, tc='d')\n",
    "    \n",
    "    kernel_sol = solvers.qp(KERNEL_MATRIX,q,G,h,A,b)\n",
    "    \n",
    "    kernel_solution = np.array(kernel_sol['x'])\n",
    "    \n",
    "    for iter, file in enumerate(glob.glob(f'./val/{class0}/*.jpg')):\n",
    "        validate_on = read_sample(file)\n",
    "        if iter == 0:\n",
    "            X_to_infer_on = validate_on\n",
    "        else:\n",
    "            X_to_infer_on = np.vstack((X_to_infer_on, validate_on))\n",
    "        infer_actual.append(-1)\n",
    "            \n",
    "    for iter, file in enumerate(glob.glob(f'./val/{class1}/*.jpg')):\n",
    "        validate_on = read_sample(file)\n",
    "        X_to_infer_on = np.vstack((X_to_infer_on, validate_on))\n",
    "        infer_actual.append(1)\n",
    "    \n",
    "    predictions = infer_on_gaussian(X_to_infer_on, only_X_data,kernel_solution,y,gamma = 0.001)\n",
    "    \n",
    "    prediciton_iterator = 0\n",
    "    \n",
    "    for iter, file in enumerate(glob.glob(f'./val/{class0}/*.jpg')):\n",
    "        if file not in classification_dict:\n",
    "            classification_dict[file] = []\n",
    "        \n",
    "        # print(predictions[prediciton_iterator])\n",
    "        classify_as = class1 if predictions[prediciton_iterator] >=0 else class0\n",
    "        classification_dict[file].append((classify_as,predictions[prediciton_iterator][0]))\n",
    "        prediciton_iterator += 1\n",
    "    \n",
    "    for iter, file in enumerate(glob.glob(f'./val/{class1}/*.jpg')):\n",
    "        if file not in classification_dict:\n",
    "            classification_dict[file] = []\n",
    "        \n",
    "        classify_as = class1 if predictions[prediciton_iterator] >=0 else class0\n",
    "        classification_dict[file].append((classify_as,predictions[prediciton_iterator][0]))\n",
    "        prediciton_iterator += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying between  0  and  1\n",
      "./train/1/4271.jpg\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.9393e+03 -1.4696e+04  9e+04  4e+00  4e-13\n",
      " 1: -1.2731e+03 -1.0480e+04  2e+04  4e-01  4e-13\n",
      " 2: -1.1845e+03 -2.6743e+03  1e+03  6e-13  4e-13\n",
      " 3: -1.4357e+03 -2.1032e+03  7e+02  6e-14  4e-13\n",
      " 4: -1.5025e+03 -1.9941e+03  5e+02  2e-12  4e-13\n",
      " 5: -1.5733e+03 -1.8712e+03  3e+02  1e-12  4e-13\n",
      " 6: -1.6192e+03 -1.7957e+03  2e+02  6e-13  4e-13\n",
      " 7: -1.6452e+03 -1.7549e+03  1e+02  5e-13  4e-13\n",
      " 8: -1.6661e+03 -1.7225e+03  6e+01  3e-13  4e-13\n",
      " 9: -1.6769e+03 -1.7068e+03  3e+01  1e-12  4e-13\n",
      "10: -1.6857e+03 -1.6947e+03  9e+00  8e-13  4e-13\n",
      "11: -1.6890e+03 -1.6904e+03  1e+00  1e-13  5e-13\n",
      "12: -1.6896e+03 -1.6897e+03  7e-02  6e-13  5e-13\n",
      "13: -1.6896e+03 -1.6896e+03  2e-03  2e-13  5e-13\n",
      "14: -1.6896e+03 -1.6896e+03  3e-05  1e-12  5e-13\n",
      "Optimal solution found.\n",
      "[-0.25849697]\n",
      "[0.92707663]\n",
      "[-2.89444727]\n",
      "[-1.65080284]\n",
      "[-0.79981767]\n",
      "[0.2138211]\n",
      "[-2.42851631]\n",
      "[-2.84277962]\n",
      "[-2.73871044]\n",
      "[-2.12557709]\n",
      "[-2.62873867]\n",
      "[-0.52659531]\n",
      "[0.2694801]\n",
      "[-0.40216408]\n",
      "[-0.6968507]\n",
      "[-2.1709807]\n",
      "[-1.34186604]\n",
      "[-0.81796406]\n",
      "[0.29275006]\n",
      "[-1.85015563]\n",
      "[-0.6640132]\n",
      "[-3.33916474]\n",
      "[-2.09394036]\n",
      "[-0.61877052]\n",
      "[-0.09606708]\n",
      "[-3.03981385]\n",
      "[-0.96734429]\n",
      "[-2.16534633]\n",
      "[-0.73977761]\n",
      "[-0.460499]\n",
      "[-1.623599]\n",
      "[0.74388204]\n",
      "[-1.86144715]\n",
      "[-0.37653603]\n",
      "[-1.91217305]\n",
      "[0.25318138]\n",
      "[-2.60216905]\n",
      "[-0.43782438]\n",
      "[-0.52193007]\n",
      "[0.93747244]\n",
      "[-1.86328154]\n",
      "[-2.38984906]\n",
      "[-0.03026591]\n",
      "[-1.13701633]\n",
      "[-0.81800456]\n",
      "[-0.52843683]\n",
      "[-1.93441502]\n",
      "[-0.61658446]\n",
      "[-0.08359649]\n",
      "[-1.33871964]\n",
      "[0.72331767]\n",
      "[0.74069403]\n",
      "[-1.09411702]\n",
      "[-0.54780308]\n",
      "[-0.98051114]\n",
      "[-0.65851234]\n",
      "[-0.9757933]\n",
      "[-2.11867708]\n",
      "[-0.88408045]\n",
      "[-1.04200056]\n",
      "[0.38010568]\n",
      "[-1.51215457]\n",
      "[0.32907581]\n",
      "[-1.3797579]\n",
      "[-1.22360837]\n",
      "[-0.77209276]\n",
      "[-1.93453317]\n",
      "[-3.23508772]\n",
      "[-1.08192043]\n",
      "[-0.57868753]\n",
      "[-1.97316801]\n",
      "[-0.32541456]\n",
      "[-2.0330047]\n",
      "[-1.04327572]\n",
      "[-0.61738194]\n",
      "[-1.21429676]\n",
      "[-2.26102193]\n",
      "[-2.47196227]\n",
      "[0.72160611]\n",
      "[-2.0012819]\n",
      "[0.04946736]\n",
      "[-0.64725164]\n",
      "[-1.20645275]\n",
      "[-3.26085084]\n",
      "[-1.31562449]\n",
      "[-1.58030137]\n",
      "[-0.89825788]\n",
      "[0.66641402]\n",
      "[-1.15226388]\n",
      "[-2.13718267]\n",
      "[-1.71480457]\n",
      "[-0.99428328]\n",
      "[-1.35571019]\n",
      "[-0.68897912]\n",
      "[-0.37239962]\n",
      "[-0.00739104]\n",
      "[-1.24753391]\n",
      "[-0.58932478]\n",
      "[0.48906903]\n",
      "[-1.9825628]\n",
      "[-2.41501828]\n",
      "[-0.00256317]\n",
      "[-0.65368761]\n",
      "[-1.94725117]\n",
      "[-3.01278755]\n",
      "[-0.36193845]\n",
      "[-0.6414093]\n",
      "[-0.57509931]\n",
      "[-2.03059344]\n",
      "[-0.88520552]\n",
      "[-0.48444721]\n",
      "[-1.13931709]\n",
      "[-1.49791426]\n",
      "[-1.21234688]\n",
      "[-2.69132279]\n",
      "[-1.41024349]\n",
      "[-2.5256976]\n",
      "[-1.48710602]\n",
      "[-0.74946029]\n",
      "[-1.56084129]\n",
      "[-1.8966321]\n",
      "[-0.93367445]\n",
      "[1.04506826]\n",
      "[-1.7670691]\n",
      "[-1.81631461]\n",
      "[-1.55949596]\n",
      "[1.11383704]\n",
      "[-2.07482359]\n",
      "[-3.01457056]\n",
      "[-0.91909144]\n",
      "[-2.85517054]\n",
      "[0.13407726]\n",
      "[0.01868896]\n",
      "[-1.95723574]\n",
      "[0.27340402]\n",
      "[0.75418697]\n",
      "[-0.42351288]\n",
      "[0.23349211]\n",
      "[-0.02603492]\n",
      "[-2.03941894]\n",
      "[-0.28261597]\n",
      "[-1.70333889]\n",
      "[-0.14184642]\n",
      "[-3.05832421]\n",
      "[-0.92125473]\n",
      "[-1.8686973]\n",
      "[0.19953744]\n",
      "[-1.97587188]\n",
      "[-1.81798652]\n",
      "[-0.36077648]\n",
      "[-2.53963389]\n",
      "[-1.50692869]\n",
      "[-0.63143724]\n",
      "[-1.84995295]\n",
      "[-2.67892083]\n",
      "[-1.142018]\n",
      "[-2.1231241]\n",
      "[-1.71353246]\n",
      "[-1.49266703]\n",
      "[-1.86399337]\n",
      "[-1.28222235]\n",
      "[-0.91668345]\n",
      "[-0.9569534]\n",
      "[-1.42188444]\n",
      "[-0.83003994]\n",
      "[0.51540962]\n",
      "[-1.11012644]\n",
      "[-0.96514899]\n",
      "[-1.68248722]\n",
      "[0.0492007]\n",
      "[-1.50367957]\n",
      "[-2.60073896]\n",
      "[-1.25435496]\n",
      "[-1.31632765]\n",
      "[0.85501289]\n",
      "[-1.0565406]\n",
      "[-1.82043325]\n",
      "[-0.3302879]\n",
      "[-1.20110852]\n",
      "[-1.94226911]\n",
      "[-0.86978612]\n",
      "[0.28240265]\n",
      "[-0.81996319]\n",
      "[-0.76989122]\n",
      "[-2.06819756]\n",
      "[0.6408584]\n",
      "[-0.14047734]\n",
      "[-2.22515204]\n",
      "[-1.73346176]\n",
      "[-1.8594993]\n",
      "[0.55183406]\n",
      "[0.48068351]\n",
      "[-0.78610893]\n",
      "[-1.05764354]\n",
      "[-2.41248747]\n",
      "[-2.4217111]\n",
      "[-2.35055708]\n",
      "[-1.74687674]\n",
      "[-1.68093142]\n",
      "[-1.8696532]\n"
     ]
    }
   ],
   "source": [
    "# for i in range(0,3):\n",
    "#     for j in range(0,3):\n",
    "#         if i < j:\n",
    "#             classify_between_two(i,j)\n",
    "\n",
    "classify_between_two(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making it parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_between_two_parallel(class0,class1,result_dict):\n",
    "    classification_dict = {}\n",
    "    print(\"Classifying between \", class0, \" and \", class1)\n",
    "    for iter, file in enumerate(glob.glob(f'./train/{class0}/*.jpg')):\n",
    "        if iter == 0:\n",
    "            # print(file)\n",
    "            X0 = read_sample(file)\n",
    "        else:\n",
    "            X0 = np.vstack((X0, read_sample(file)))\n",
    "        \n",
    "    for iter, file in enumerate(glob.glob(f'./train/{class1}/*.jpg')):\n",
    "        if iter == 0:\n",
    "            X1 = read_sample(file)\n",
    "            print(file)\n",
    "        else:\n",
    "            X1 = np.vstack((X1, read_sample(file)))\n",
    "    \n",
    "    only_X_data = np.vstack((X0, X1))\n",
    "\n",
    "    all_X = np.vstack((-1*X0, X1))\n",
    "    y = np.vstack((-1*np.ones((X0.shape[0], 1)), np.ones((X1.shape[0], 1))))\n",
    "\n",
    "    negative_test_cases = X0.shape[0]\n",
    "    positive_test_cases = X1.shape[0]\n",
    "    number_of_test_case = all_X.shape[0]\n",
    "#     for j in range(0,3):\n",
    "#         if i < j:\n",
    "#             classify_between_two(i,j)X.shape[0]\n",
    "\n",
    "    gamma = 0.001\n",
    "    \n",
    "    KERNEL_MATRIX = (np.outer(y,y))* (np.exp(-gamma * cdist(only_X_data, only_X_data, 'sqeuclidean')))\n",
    "    \n",
    "    q = -1*np.ones((number_of_test_case, 1))\n",
    "    G = np.vstack((-1*np.eye(number_of_test_case), np.eye(number_of_test_case)))\n",
    "    h = np.vstack((np.zeros((number_of_test_case, 1)), regulising_factor*np.ones((number_of_test_case, 1))))\n",
    "    A =  np.hstack((-1*np.ones((1, negative_test_cases)), np.ones((1, positive_test_cases))))\n",
    "    b = np.zeros((1))\n",
    "    \n",
    "    \n",
    "    KERNEL_MATRIX = matrix(KERNEL_MATRIX, tc='d')\n",
    "    q = matrix(q, tc='d')\n",
    "    G = matrix(G, tc='d')\n",
    "    h = matrix(h, tc='d')\n",
    "    A = matrix(A, tc='d')\n",
    "    b = matrix(b, tc='d')\n",
    "    \n",
    "    kernel_sol = solvers.qp(KERNEL_MATRIX,q,G,h,A,b)\n",
    "    \n",
    "    kernel_solution = np.array(kernel_sol['x'])\n",
    "    \n",
    "    for iter, file in enumerate(glob.glob(f'./val/{class0}/*.jpg')):\n",
    "        validate_on = read_sample(file)\n",
    "        if iter == 0:\n",
    "            X_to_infer_on = validate_on\n",
    "        else:\n",
    "            X_to_infer_on = np.vstack((X_to_infer_on, validate_on))\n",
    "        infer_actual.append(-1)\n",
    "            \n",
    "    for iter, file in enumerate(glob.glob(f'./val/{class1}/*.jpg')):\n",
    "        validate_on = read_sample(file)\n",
    "        X_to_infer_on = np.vstack((X_to_infer_on, validate_on))\n",
    "        infer_actual.append(1)\n",
    "    \n",
    "    predictions = infer_on_gaussian(X_to_infer_on, only_X_data,kernel_solution,y,gamma = 0.001)\n",
    "    \n",
    "    prediciton_iterator = 0\n",
    "    \n",
    "    for iter, file in enumerate(glob.glob(f'./val/{class0}/*.jpg')):\n",
    "        if file not in classification_dict:\n",
    "            classification_dict[file] = []\n",
    "        \n",
    "        # print(predictions)\n",
    "        \n",
    "        classify_as = class1 if predictions[prediciton_iterator] >=0 else class0\n",
    "        classification_dict[file].append((classify_as,predictions[prediciton_iterator][0]))\n",
    "        prediciton_iterator += 1\n",
    "    \n",
    "    for iter, file in enumerate(glob.glob(f'./val/{class1}/*.jpg')):\n",
    "        if file not in classification_dict:\n",
    "            classification_dict[file] = []\n",
    "        \n",
    "        classify_as = class1 if predictions[prediciton_iterator] >=0 else class0\n",
    "        classification_dict[file].append((classify_as,predictions[prediciton_iterator][0]))\n",
    "        prediciton_iterator += 1\n",
    "        \n",
    "    \n",
    "    result_dict[(class0, class1)] = classification_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying between Classifying between Classifying between    00 1   and  and  and   2 2\n",
      "1\n",
      "\n",
      "./train/1/4271.jpg\n",
      "./train/2/21230.jpg\n",
      "./train/2/21230.jpg\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.9393e+03 -1.4696e+04  9e+04  4e+00  4e-13\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -1.1860e+03 -1.2578e+04  7e+04  3e+00  2e-13\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -2.8766e+03 -1.4989e+04  8e+04  3e+00  6e-13\n",
      " 1: -1.2731e+03 -1.0480e+04  2e+04  4e-01  4e-13\n",
      " 1: -7.3522e+02 -8.1296e+03  1e+04  4e-01  3e-13\n",
      " 1: -1.9324e+03 -1.0948e+04  1e+04  2e-01  7e-13\n",
      " 2: -1.1845e+03 -2.6743e+03  1e+03  6e-13  4e-13\n",
      " 2: -5.6455e+02 -1.6716e+03  1e+03  8e-03  2e-13\n",
      " 2: -2.0564e+03 -3.5589e+03  2e+03  2e-02  5e-13\n",
      " 3: -1.4357e+03 -2.1032e+03  7e+02  6e-14  4e-13\n",
      " 3: -6.6510e+02 -1.3790e+03  7e+02  5e-03  2e-13\n",
      " 3: -2.4060e+03 -2.9060e+03  5e+02  6e-03  6e-13\n",
      " 4: -1.5025e+03 -1.9941e+03  5e+02  2e-12  4e-13\n",
      " 4: -7.4937e+02 -1.1580e+03  4e+02  2e-03  2e-13\n",
      " 4: -2.5331e+03 -2.7355e+03  2e+02  2e-03  6e-13\n",
      " 5: -7.7440e+02 -1.1039e+03  3e+02  2e-03  2e-13\n",
      " 5: -1.5733e+03 -1.8712e+03  3e+02  1e-12  4e-13\n",
      " 5: -2.5884e+03 -2.6601e+03  7e+01  5e-04  6e-13\n",
      " 6: -8.0472e+02 -1.0385e+03  2e+02  9e-04  2e-13\n",
      " 6: -1.6192e+03 -1.7957e+03  2e+02  6e-13  4e-13\n",
      " 6: -2.6122e+03 -2.6291e+03  2e+01  1e-04  7e-13\n",
      " 7: -8.3295e+02 -9.7750e+02  1e+02  3e-04  2e-13\n",
      " 7: -1.6452e+03 -1.7549e+03  1e+02  5e-13  4e-13\n",
      " 7: -2.6185e+03 -2.6211e+03  3e+00  5e-06  7e-13\n",
      " 8: -8.4698e+02 -9.5141e+02  1e+02  2e-04  2e-13\n",
      " 8: -1.6661e+03 -1.7225e+03  6e+01  3e-13  4e-13\n",
      " 8: -2.6196e+03 -2.6199e+03  3e-01  5e-07  7e-13\n",
      " 9: -8.6050e+02 -9.2677e+02  7e+01  1e-04  2e-13\n",
      " 9: -1.6769e+03 -1.7068e+03  3e+01  1e-12  4e-13\n",
      " 9: -2.6197e+03 -2.6197e+03  1e-02  2e-08  7e-13\n",
      "10: -8.7205e+02 -9.0692e+02  4e+01  5e-05  2e-13\n",
      "10: -1.6857e+03 -1.6947e+03  9e+00  8e-13  4e-13\n",
      "10: -2.6197e+03 -2.6197e+03  2e-04  3e-10  7e-13\n",
      "Optimal solution found.\n",
      "11: -8.7866e+02 -8.9617e+02  2e+01  2e-05  2e-13\n",
      "11: -1.6890e+03 -1.6904e+03  1e+00  1e-13  5e-13\n",
      "12: -8.8279e+02 -8.8974e+02  7e+00  6e-06  2e-13\n",
      "12: -1.6896e+03 -1.6897e+03  7e-02  6e-13  5e-13\n",
      "13: -8.8527e+02 -8.8638e+02  1e+00  8e-07  3e-13\n",
      "13: -1.6896e+03 -1.6896e+03  2e-03  2e-13  5e-13\n",
      "14: -8.8573e+02 -8.8578e+02  5e-02  2e-08  3e-13\n",
      "14: -1.6896e+03 -1.6896e+03  3e-05  1e-12  5e-13\n",
      "Optimal solution found.\n",
      "15: -8.8576e+02 -8.8576e+02  1e-03  6e-10  3e-13\n",
      "16: -8.8576e+02 -8.8576e+02  3e-05  1e-11  3e-13\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 6\n",
    "\n",
    "class_pairs = [(i, j) for i in range(num_classes) for j in range(i+1, num_classes)]\n",
    "\n",
    "manager = multiprocessing.Manager()\n",
    "result_dict = manager.dict()\n",
    "\n",
    "pool = multiprocessing.Pool(processes=multiprocessing.cpu_count())\n",
    "\n",
    "for class_pair in class_pairs:\n",
    "    pool.apply_async(classify_between_two_parallel, args=(class_pair[0], class_pair[1], result_dict))\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "final_classification_dict = {}\n",
    "for classification_dict in result_dict.values():\n",
    "    for key, value in classification_dict.items():\n",
    "        if key not in final_classification_dict:\n",
    "            final_classification_dict[key] = []\n",
    "        final_classification_dict[key].extend(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = {}\n",
    "for file, classifications in final_classification_dict.items():\n",
    "    \n",
    "    votes = {}\n",
    "    \n",
    "    for classify_as, score in classifications:\n",
    "        if classify_as not in votes:\n",
    "            votes[classify_as] = (0,0)\n",
    "        \n",
    "        number_of_vote, score_till_now = votes[classify_as]\n",
    "        votes[classify_as] = (number_of_vote + 1, score_till_now + abs(score))\n",
    "        \n",
    "    max_votes = max(votes, key=lambda k: (votes[k][0], votes[k][1]))\n",
    "\n",
    "    \n",
    "    final_labels[file] = max_votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(0,num_classes):\n",
    "    for iter, file in enumerate(glob.glob(f'./val/{i}/*.jpg')):\n",
    "        total += 1\n",
    "        if final_labels[file] == i:\n",
    "            correct += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for multi classification is 92.0%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy for multi classification is {(100*correct)/total}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39m3\u001b[39m):\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m, file \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(glob\u001b[39m.\u001b[39mglob(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./train/\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m/*.jpg\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m----> 6\u001b[0m         \u001b[39mif\u001b[39;00m X_multi_class \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m             \u001b[39m# print(file)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m             X_multi_class \u001b[39m=\u001b[39m read_sample(file)\n\u001b[1;32m      9\u001b[0m             y_multi_class \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([i])\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "X_multi_class = None\n",
    "y = None\n",
    "\n",
    "for i in range(0,num_classes):\n",
    "    for iter, file in enumerate(glob.glob(f'./train/{i}/*.jpg')):\n",
    "        if X_multi_class is None:\n",
    "            X_multi_class = read_sample(file)\n",
    "            y_multi_class = np.array([i])\n",
    "        else:\n",
    "            X_multi_class = np.vstack((X_multi_class, read_sample(file)))\n",
    "            y_multi_class = np.vstack((y, np.array([i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ski_svm_gauss = svm.SVC(kernel='rbf', gamma=gamma)\n",
    "\n",
    "ski_svm_gauss.fit(X_multi_class,y_multi_class)\n",
    "\n",
    "num_support_vectors = len(ski_svm_gauss.support_vectors_)\n",
    "print(f\"Number of Support Vectors: {num_support_vectors}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(0,num_classes):\n",
    "    for iter, file in enumerate(glob.glob(f'./train/{i}/*.jpg')):\n",
    "        total += 1 \n",
    "        validate_on = read_sample(file)\n",
    "        if ski_svm_gauss.predict([validate_on]) == 0:\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy with SKLearn on gaussian for multi class is: {(100*correct)/total} %\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "733",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
